# Feedback-Mechanisms-for-LLM_based-AI-Agents

This project lists the files related to the Feedback Mechanisms of LLM_based AI agents.

## ðŸ”¥ Updates

- [09/2025] Congratulation! ðŸ”¥ Our work has been accepted by **IJCAI2025** [A Survey on the Feedback Mechanism of LLM-based AI Agents](https://www.ijcai.org/proceedings/2025/1175) ðŸ”¥ paper accepted
- [05/2025] Create ðŸ”¥[Feedback-Mechanisms-for-LLM_based-AI-Agents]([https://github.com/kevinson7515/VC-Bench](https://github.com/kevinson7515/Agents-Feedback-Mechanisms)))ðŸ”¥ repository


## ðŸ“£ Overview

### A Survey on the Feedback Mechanism of LLM-based AI Agents

Large language models (LLMs) are increasingly being adopted to develop general-purpose AI agents. However, it remains challenging for these LLM-based AI agents to efficiently learn from feedback and iteratively optimize their strategies. To address this challenge, tremendous efforts have been dedicated to designing diverse feedback mechanisms for LLM-based AI agents. To provide a comprehensive overview of this rapidly evolving field, this paper presents a systematic review of these studies, offering a holistic perspective on the feedback mechanisms in LLM-based AI agents. We begin by discussing the construction of LLMbased AI agents, introducing a generalized framework that encapsulates much of the existing work. Next, we delve into the exploration of feedback mechanisms, categorizing them into four distinct types: internal feedback, external feedback, multiagent feedback, and human feedback. Additionally, we provide an overview of evaluation protocols and benchmarks specifically tailored for LLM-based AI agents. Finally, we highlight the significant challenges and identify potential directions for future studies.

## ðŸŽ“ Papers

### Survey

- [2023/08] A survey on large language model based autonomous agents | [[Paper]](https://arxiv.org/abs/2308.11432)
- [2024/01] Agent AI: Surveying the Horizons of Multimodal Interaction | [[Paper]](https://arxiv.org/abs/2401.03568)
- [2023/08] Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies | [[Paper]](https://arxiv.org/abs/2308.03188)
- [2023/09] The rise and potential of large language model based agents: A survey | [[Paper]](https://arxiv.org/abs/2309.07864)
- [2024/01] Exploring large language model based intelligent agents: Definitions, methods, and prospects | [[Paper]](https://arxiv.org/abs/2401.03428)
- [2024/02] Large Multimodal Agents: A Survey | [[Paper]](https://arxiv.org/abs/2402.15116)

### Feedback Mechanisms

#### Internal Feedback

- [2023/03] Self-refine: Iterative refinement with self-feedback | [[Paper]](https://arxiv.org/abs/2303.17651)
- [2022/10] ReAct: Synergizing Reasoning and Acting in Language Models | [[Paper]](https://arxiv.org/abs/2210.03629)
- [2022/11] Generating sequences by learning to self-correct | [[Paper]]
- [2023/03] Reflexion: Language Agents with Verbal Reinforcement Learning | [[Paper]](https://arxiv.org/abs/2303.11366)
- [2023/05] AdaPlanner: Adaptive Planning from Feedback with Language Models | [[Paper]]
- [2024/02] Mirror: Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning | [[Paper]](https://arxiv.org/abs/2402.14963)
- [2023/08] Expel: Llm agents are experiential learners | [[Paper]]
- [2024/03] Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents | [[Paper]](https://arxiv.org/abs/2403.02502)
- [2024/02] PreAct: Prediction Enhances Agent's Planning Ability | [[Paper]](https://arxiv.org/abs/2402.11534)
- [2024/02] RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents | [[Paper]](https://arxiv.org/abs/2402.03610)
- [2023/04] Generative agents: Interactive simulacra of human behavior | [[Paper]](https://arxiv.org/abs/2304.03442)
- [2023/08] SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning | [[Paper]](https://arxiv.org/abs/2308.00436)
- [2023/08] Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization | [[Paper]]

#### External Feedback

- [2023/03] Reflexion: Language Agents with Verbal Reinforcement Learning | [[Paper]](https://arxiv.org/abs/2303.11366)
- [2023/05] Voyager: An Open-Ended Embodied Agent with Large Language Models | [[Paper]]
- [2023/03] PaLM-E: An Embodied Multimodal Language Model | [[Paper]](https://arxiv.org/abs/2303.03378)
- [2023/11] JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models | [[Paper]](https://arxiv.org/abs/2311.05997)
- [2020/10] Keep CALM and Explore: Language Models for Action Generation in Text-based Games | [[Paper]](https://arxiv.org/abs/2010.02903)
- [2024/03] Cradle: Empowering Foundation Agents Towards General Computer Control | [[Paper]](https://arxiv.org/abs/2403.03186)
- [2022/12] RT-1: Robotics Transformer for Real-World Control at Scale | [[Paper]](https://arxiv.org/abs/2212.06817)
- [2023/07] RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control | [[Paper]](https://arxiv.org/abs/2307.15818)
- [2021/12] WebGPT: Browser-assisted question-answering with human feedback | [[Paper]](https://arxiv.org/abs/2112.09332)
- [2021/01] CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges | [[Paper]](https://arxiv.org/abs/2401.07339)
- [2024/03] QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback-based Self-Correction | [[Paper]](https://arxiv.org/abs/2403.11886)
- [2024/02] StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback | [[Paper]](https://arxiv.org/abs/2402.01391)
- [2022/07] CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning | [[Paper]](https://arxiv.org/abs/2207.01780)
- [2024/023] WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment | [[Paper]](https://arxiv.org/abs/2402.12275)

#### Multi-Agent Feedback

- [2023/05] Improving Factuality and Reasoning in Language Models through Multiagent Debate | [[Paper]](https://arxiv.org/abs/2305.14325)
- [2024/02] AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls | [[Paper]](https://arxiv.org/abs/2402.04253#:~:text=We introduce AnyTool%2C a large language model agent,vast array of tools in addressing user queries.)
- [2023/08] InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent | [[Paper]](https://arxiv.org/abs/2308.01552)
- [2023/04] ChatLLM Network: More brains, More intelligence | [[Paper]]
- [2023/08] MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework | [[Paper]](https://arxiv.org/abs/2308.00352)
- [2023/08] Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations | [[Paper]](https://arxiv.org/abs/2308.16505)
- [2023/08] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate | [[Paper]](https://arxiv.org/abs/2308.07201)

#### Human Feedback

- [2024/02] Large Language Model-based Human-Agent Collaboration for Complex Task Solving | [[Paper]]
- [2022/03] Training language models to follow instructions with human feedback | [[Paper]](https://arxiv.org/abs/2203.02155)
- [2023/05] RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs | [[Paper]](https://arxiv.org/abs/2305.08844)
- [2019/02] Deep reinforcement learning from policy-dependent human feedback | [[Paper]](https://arxiv.org/abs/1902.04257)
- [2024/07] PrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models | [[Paper]](https://arxiv.org/abs/2407.08213#:~:text=To address these challenges%2C we introduce PrefCLM%2C a,language models (LLMs) as simulated teachers in PbRL.)
- [2017/09] Deep tamer: Interactive agent shaping in high-dimensional state spaces | [[Paper]](https://arxiv.org/abs/1709.10163#:~:text=In this paper%2C we do both%3A we propose,to learn complex tasks in just a sho)
- [2017/06] Deep reinforcement learning from human preferences | [[Paper]]
- [2022/09] Improving alignment of dialogue agents via targeted human judgements | [[Paper]]
- [2021/12] WebGPT: Browser-assisted question-answering with human feedback | [[Paper]](https://arxiv.org/abs/2112.09332)
- [2022/11] Improving Multimodal Interactive Agents with Reinforcement Learning from Human Feedback | [[Paper]](https://arxiv.org/abs/2211.11602)

### Evaluation&Benchmark

- [2018/03] FEVER: a large-scale dataset for Fact Extraction and VERification | [[Paper]](https://arxiv.org/abs/1803.05355)
- [2023/06] Mind2Web: Towards a Generalist Agent for the Web | [[Paper]](https://arxiv.org/abs/2306.06070)
- [2024/03] SocialBench: Sociality Evaluation of Role-Playing Conversational Agents | [[Paper]](https://arxiv.org/abs/2403.13679)
- [2023/08] Chateval: Towards better llm-based evaluators through multi-agent debate | [[Paper]](https://arxiv.org/abs/2308.07201)
- [2024/10] Agent-as-a-judge: Evaluate agents with agents | [[Paper]]
- [2023/08] AgentBench: Evaluating LLMs as Agents | [[Paper]](https://arxiv.org/abs/2308.03688#:~:text=We present AgentBench%2C a multi-dimensional evolving benchmark that,reasoning and decision-making abilities in a multi-turn ope)
- [2020/10] ALFWorld: Aligning Text and Embodied Environments for Interactive Learning | [[Paper]](https://arxiv.org/abs/2010.03768)
- [2022/09] Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering | [[Paper]](https://arxiv.org/abs/2209.09513)
- [2019/10] Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning | [[Paper]](https://arxiv.org/abs/1910.11956)
- [2023/04] Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback | [[Paper]](https://arxiv.org/abs/2304.10750)
- [2021/01] Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies | [[Paper]](https://arxiv.org/abs/2101.02235#:~:text=In this work%2C we introduce StrategyQA%2C a question,question%2C and should be inferred using a strategy.)
- [2018/09] HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering | [[Paper]](https://arxiv.org/abs/1809.09600)
- [2021/07] Evaluating large language models trained on code | [[Paper]]
- [2021/08] Program synthesis with large language models | [[Paper]](https://arxiv.org/abs/2108.07732))
- [2019/10] Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning | [[Paper]](https://arxiv.org/abs/1910.10897)
- [2023/04] Tool learning with foundation models | [[Paper]]
- [2024/02] TravelPlanner: A Benchmark for Real-World Planning with Language Agents | [[Paper]](https://arxiv.org/abs/2402.01622)
- [2022/07] WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents | [[Paper]](https://arxiv.org/abs/2207.01206)
- [2023/05] Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark | [[Paper]](https://arxiv.org/abs/2305.14938)
- [2024/04] AutoWebGLM: A Large Language Model-based Web Navigating Agent | [[Paper]](https://arxiv.org/abs/2404.03648)
- [2023/07] RoCo: Dialectic Multi-Robot Collaboration with Large Language Models | [[Paper]](https://arxiv.org/abs/2307.04738)
- [2024/01] ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios | [[Paper]](https://arxiv.org/abs/2401.00741)
- [2023/10] SWE-bench: Can Language Models Resolve Real-World GitHub Issues? | [[Paper]](https://arxiv.org/abs/2310.06770)
- [2023/10] Open X-Embodiment: Robotic Learning Datasets and RT-X Models | [[Paper]](https://arxiv.org/abs/2310.08864)
- [2023/07] WebArena: A Realistic Web Environment for Building Autonomous Agents | [[Paper]](https://arxiv.org/abs/2307.13854)
- [2024/01] WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models | [[Paper]](https://arxiv.org/abs/2401.13919)

### Others

- [2023/03] GPT-4 Technical Report | [[Paper]](https://arxiv.org/abs/2303.08774)
- [2023/06] Demystifying GPT Self-Repair for Code Generation | [[Paper]](https://export.arxiv.org/abs/2306.09896v2)
- [2023/10] MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models | [[Paper]](https://arxiv.org/abs/2310.11954)
- [2024/03] VideoAgent: Long-form Video Understanding with Large Language Model as Agent | [[Paper]](https://arxiv.org/abs/2403.10517)
- [2024/04] DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model | [[Paper]](https://arxiv.org/abs/2404.01342)
